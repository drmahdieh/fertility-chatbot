import os
import streamlit as st
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.llms import HuggingFaceHub
from langchain.chains import RetrievalQA

# -----------------------------
# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡
# -----------------------------
os.environ["HUGGINGFACEHUB_API_TOKEN"] = "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"

PDF_PATH = "data/infertility_guide.pdf"

# -----------------------------
# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ PDF
# -----------------------------
@st.cache_resource
def load_and_split_pdf(_pdf_path):
    loader = PyPDFLoader(_pdf_path)
    docs = loader.load()
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    return text_splitter.split_documents(docs)

@st.cache_resource
def create_vectorstore(_chunks):
    embeddings = HuggingFaceEmbeddings()
    return FAISS.from_documents(_chunks, embeddings)

# -----------------------------
# Ø§ÛŒØ¬Ø§Ø¯ LLM Ùˆ Ø²Ù†Ø¬ÛŒØ±Ù‡ QA
# -----------------------------
@st.cache_resource
def create_qa_chain(_vectorstore):
    llm = HuggingFaceHub(
        repo_id="meta-llama/Meta-Llama-3-8B-Instruct",
        model_kwargs={"temperature": 0.1, "max_length": 512}
    )
    return RetrievalQA.from_chain_type(
        llm=llm,
        retriever=_vectorstore.as_retriever(),
        return_source_documents=True
    )

# -----------------------------
# Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Streamlit
# -----------------------------
st.title("ğŸ¤– Ú†Øªâ€ŒØ¨Ø§Øª Ù…Ø´Ø§ÙˆØ±Ù‡ PDF - Llama 3")
st.write("Ø§ÛŒÙ† Ú†Øªâ€ŒØ¨Ø§Øª Ø¨Ù‡ PDF Ù…ØªØµÙ„ Ø§Ø³Øª Ùˆ Ø§Ø² Ù…Ø¯Ù„ Llama 3 Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.")

chunks = load_and_split_pdf(PDF_PATH)
vectorstore = create_vectorstore(chunks)
qa_chain = create_qa_chain(vectorstore)

user_question = st.text_input("Ø³ÙˆØ§Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù¾Ø±Ø³ÛŒØ¯:")

if user_question:
    with st.spinner("Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´..."):
        result = qa_chain.invoke({"query": user_question})
        st.subheader("Ù¾Ø§Ø³Ø®:")
        st.write(result["result"])

        # Ù†Ù…Ø§ÛŒØ´ Ù…Ù†Ø§Ø¨Ø¹
        st.subheader("Ù…Ù†Ø§Ø¨Ø¹:")
        for doc in result["source_documents"]:
            st.write(f"- ØµÙØ­Ù‡: {doc.metadata.get('page', 'Ù†Ø§Ù…Ø´Ø®Øµ')}")
